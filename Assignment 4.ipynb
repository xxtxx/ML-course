{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Mining: Assignment 4\n",
    "\n",
    "Please complete all assignments in this notebook. You should submit this notebook, as well as a PDF version (See File > Download as)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from preamble import *\n",
    "plt.rcParams['savefig.dpi'] = 100 # This controls the size of your figures\n",
    "# Comment out and restart notebook if you only want the last output of each cell.\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation (3 points)\n",
    "\n",
    "Figure 1 illustrates a simple neural network model.\n",
    "\n",
    "![Figure 1](images/assignment/small-net.png)\n",
    "\n",
    "It has single input $x$, two layers with one neuron each. The activation function of both layers is ReLU. \n",
    "\n",
    "The parameters $w_0$ and $w_1$ (no biases) are initialized to the following values $w_0 = 1$ and $w_1 = 2$. Implement a single update step of the gradient descent algorithm by hand. Run the update state for the following two data points:\n",
    "\n",
    "* $(1, 2)$ \n",
    "* $(2, 3)$\n",
    "\n",
    "The goal is to model the relationship between two continuous variables. The learning rate is set to $0.1$\n",
    "\n",
    "Provide the solution in the following format:\n",
    "\n",
    "- A choice for a loss function \n",
    "- Compute graph for training the neural network\n",
    "- Partial derivative expression for each of the parameters in the model\n",
    "- The update expression for each of the parameters for each of the data-points\n",
    "- The final value of both parameters after the single step in the gradient descent algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Deep Models (3 points)\n",
    "\n",
    "The model in the example code below performs poorly as its depth increases. Train this model on the MNIST digit detection task. \n",
    "\n",
    "Examine its training performance by gradually increasing its depth:\n",
    "- Set the depth to 1 hidden layer\n",
    "- Set the depth to 2 hidden layers\n",
    "- Set the depth to 3 hidden layers\n",
    "\n",
    "Modify the model such that you improve its performance when its depth increases. Train the new model again for the different depths:\n",
    "- Set the depth to 1 hidden layer\n",
    "- Set the depth to 2 hidden layers\n",
    "- Set the depth to 3 hidden layers\n",
    "\n",
    "Submit an explanation for the limitation of the original model. Explain your modification. \n",
    "Submit your code and 6 plots (can be overlaid) for the training performance of both models with different depths. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (You don't need to change this part of the code)\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (You don't need to change this part of the code)\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this parameter to change the depth of the model\n",
    "number_hidden_layers = 1  # Number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,), activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "while number_hidden_layers > 1:\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    number_hidden_layers -= 1\n",
    "\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training (You don't need to change this part of the code)\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks for Filtering (2 points)\n",
    "\n",
    "Convolutional neural networks are well suited for analyzing images. They can be used to apply various image filtering operations. \n",
    "\n",
    "The goal of this exercise is to design a CNN model that applies 2 filters to its input images. The input images are 128x128 RGB color images, encoded as 128x128x3 tensor with floating point value normalized between 0 and 1. The RGB format is such that the pixels address by: [:, :, 0] encode the red pixels of the image, the pixels addressed by [:, :, 1] define the green pixels and pixels addressed by [:, :, 2] define the blue pixels. \n",
    "\n",
    "Design a convolutional neural network that will: \n",
    "1. Apply the sepia filter to the image\n",
    "2. Apply Gaussian smoothing to the image\n",
    "\n",
    "Use the specification of the sepia and the Gaussian filter below. \n",
    "\n",
    "You answer should contain:\n",
    "    - The definition of the architecture of the CNN\n",
    "        - Number of layers\n",
    "        - Number of filters per layer\n",
    "        - Shape of the filter per layer\n",
    "    - Values of each of the parameters of the CNN when using a 5x5 Gaussian smoothing filter\n",
    "    - The dimensions of the output image when a 5x5 Gaussian smothing is applied\n",
    "\n",
    "\n",
    "The sepia effect gives warmth and a feel of vintage to photographs. The sepia filter is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "R_o = (R_i * .393) + (G_i *.769) + (B_i * .189)\\\\\n",
    "G_o = (R_i * .349) + (G_i *.686) + (B_i * .168)\\\\\n",
    "B_o = (R_i * .272) + (G_i *.534) + (B_i * .131)\n",
    "\\end{equation}\n",
    "\n",
    "Gaussian blurring is an effect that reduces the noise and details in an image. \n",
    "Gaussian smoothing filter:\n",
    "$$G(x, y)=\\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2+y^2}{2\\sigma^2}}$$\n",
    "\n",
    "- A discretized version of the filter is given by the following table:\n",
    "\n",
    "<table>\n",
    "<tr><td>1</td><td>4</td><td>7</td><td>4</td><td>1</td></tr>\n",
    "<tr><td>4</td><td>16</td><td>26</td><td>16</td><td>4</td></tr>\n",
    "<tr><td>7</td><td>26</td><td>41</td><td>26</td><td>7</td></tr>\n",
    "<tr><td>4</td><td>16</td><td>26</td><td>16</td><td>4</td></tr>\n",
    "<tr><td>1</td><td>4</td><td>7</td><td>4</td><td>1</td></tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "- To normalize the filter response, each value should divided by $273$. This is a truncated discretized Gaussian filter with a $\\sigma$ of 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design (2 Points)\n",
    "\n",
    "Various decisions need to be made in a modeling process to address specific properties of the data and the modeling goal. In this task, you are given a description of a data structure and a goal for which you need to design a model. \n",
    "\n",
    "Produce a figure depicting your model. Briefly explain the figure and justify all decisions made in the modeling process. In detail, describe at least: \n",
    "- Input data format\n",
    "- Number of layers\n",
    "- Type of layers (Dense, Recurrent, Convolutional - 1D, 2D, 3D)\n",
    "- Regularization\n",
    "- Model output\n",
    "- Loss function\n",
    "\n",
    "The training and execution procedures for the model may differ, so you can use different descriptions for both. \n",
    "\n",
    "*Data and goal description:*\n",
    "\n",
    "The goal of this task is to generate captions for short video clips. \n",
    "\n",
    "The video data is structured as sequences of color images. The model needs to be able to process a number of consecutive images that form a short video clip. The training data consists of video clips (few seconds) and a short caption (5-10 words). \n",
    "\n",
    "For simplicity, the accuracy of the model is evaluated on the exact prediction of the caption. In other words, the model needs to produce correctly the specific words in a specific order for each video. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MNIST Calculator (5 points)\n",
    "\n",
    "During the lectures you have seen a CNN model that can be successfully trained to classify the MNIST images. You have also seen how a RNN model that can be trained to implement addition of two numbers. \n",
    "\n",
    "Using the KERAS (or TensorFlow) library, design and train a model that can learn how to add numbers directly from the MNIST image data. More specifically, the model should input a sequence of a set of images and produces a cumulative sum of the numbers represented by the digits in the images.\n",
    "\n",
    "For example:\n",
    "\n",
    "Input 1: ![294](images/294.png)\n",
    "\n",
    "Input 2: ![61](images/61.png)\n",
    "\n",
    "Output: 355\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
