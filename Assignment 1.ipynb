{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Mining: Assignment 1\n",
    "\n",
    "Please complete all assignments in this notebook. You should submit this notebook, as well as a PDF version (See File > Download as)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from preamble import *\n",
    "plt.rcParams['savefig.dpi'] = 100 # This controls the size of your figures\n",
    "# Comment out and restart notebook if you only want the last output of each cell.\n",
    "InteractiveShell.ast_node_interactivity = \"all\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten digit recognition (5 points, 1+2+2)\n",
    "The [MNIST dataset](https://www.openml.org/d/554) contains 70,000 images of handwritten digits (0-9) represented by 28 by 28 pixel values. We can easily download it from OpenML and visualize one of the examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a temporary read-only OpenML key. Replace with your own key later. \n",
    "oml.config.apikey = '11e82c8d91c5abece86f424369c71590'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x110beff98>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 5\n"
     ]
    },
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1R5cGUgL0NhdGFsb2cgL1BhZ2VzIDIgMCBSID4+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\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFdCAYAAAA9hbc/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110ba1208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_data = oml.datasets.get_dataset(554) # Download MNIST data\n",
    "# Get the predictors X and the labels y\n",
    "X, y = mnist_data.get_data(target=mnist_data.default_target_attribute); \n",
    "# Take the first example, reshape to a 28x28 image and plot\n",
    "plt.imshow(X[0].reshape(28, 28), cmap=plt.cm.gray_r) \n",
    "print(\"Class label:\",y[0]) # Print the correct class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate a k-Nearest Neighbor classifier with its default settings.\n",
    "    - Use the first 60,000 examples as the training set and the last 10,000 as the test set\n",
    "    - What is the predictive accuracy?\n",
    "    - Find a few misclassifications, and plot them together with the true labels (as above). Are these images really hard to classify?\n",
    "- Optimize the value for the number of neighbors $k$ (keep $k$ < 50) on a stratified subsample (e.g. 10%) of the data\n",
    "    - Use 10-fold crossvalidation and plot $k$ against the misclassification rate. Which value of $k$ should you pick?\n",
    "    - Do the same but with 100 bootstrapping repeats. Are the results different? Explain.\n",
    "- Compare kNN against the linear classification models that we have covered in the course (logistic regression and linear SVMs).\n",
    "    - First use the default hyperparameter settings.\n",
    "    - Next, optimize for the degree of regularization ($C$) and choice of penalty (L1/L2). Again, plot the accuracy while increasing the degree of regularization for different penalties. Interpret the results. \n",
    "    - Report is the optimal performance. Can you get better results than kNN?\n",
    "    \n",
    "Report all results clearly and interpret the results. \n",
    "\n",
    "Hint: while prototyping/bugfixing, you can speed up experiments by taking a smaller sample of the data, but report your results as indicated above.  \n",
    "Hint: you can easily take a 10% stratified subsample in scikit-learn like this, and then continue with X_sample and y_sample. You can also use this subsample in the 3rd subquestion if it takes too long to run in on the whole dataset.\n",
    "```X_sample, _, y_sample, _ = train_test_split(X, y, train_size=0.1, stratify=y)```  \n",
    "Hint: the $C$ parameter is typically varied on a log scale between $2^{-15}$ and $2^{15}$. You can also use something like [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]. The important thing is that you check that the optimal value lies within the range that you checked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection (4 points (2+2))\n",
    "Study how RandomForest hyperparameters interact on the Ionosphere dataset (OpenML ID 59).\n",
    "\n",
    "- Optimize a RandomForest, varying both $n\\_estimators$ and $max\\_features$ at the same time. Use a nested cross-validation and a grid search (or random search) over the possible values, and measure the AUC. Explore how fine-grained this grid/random search can be, given your computational resources. What is the optimal AUC performance you find?\n",
    "- Again, vary both hyperparameters, but this time use a grid search and visualize the results as a plot (heatmap) $n\\_estimators \\times max\\_features \\rightarrow AUC$ with AUC visualized as the color of the data point. Try to make the grid as fine as possible. Interpret the results. Can you explain your observations? What did you learn about tuning RandomForests?\n",
    "\n",
    "Hint: Running this experiment can take a while, so start early and use a feasible grid/random search. Start with a coarse grid or few random search iterations.  \n",
    "Hint: Use a log scale (1,2,4,8,16,...,512) for $n\\_estimators$. Vary $max\\_features$ linearly between 1 and the total number of features. Note that, if you give $max\\_features$ a float value, it will use it as [the percentage of the total number of features](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). Hence, you can explore the values [0.1,0.2,0.3,...,0.9]  \n",
    "Hint: We've shown how to do a nested cross-validation in class. You can also pass the evaluation measure to ```cross_val_score``` using the ```scoring``` attribute.\n",
    "Hint: Note that in the first question, we are not interested in the actual values of the optimal hyperparameters, only in their AUC performance. Indeed, you will possibly get different optimal hyperparameters in each iteration of the outer CV. In the second question, we do a single grid search, and hence we can retrieve and visualize the hyperparameter values and their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ionosphere = oml.datasets.get_dataset(59) # Download Ionosphere data\n",
    "# Get the predictors X and the labels y\n",
    "X, y = ionosphere.get_data(target=ionosphere.default_target_attribute); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree heuristics (1 point)\n",
    "Consider the toy training set created below. It predicts whether your date agrees to go out with you depending on the weather.\n",
    "\n",
    "Learn a decision tree:\n",
    "\n",
    "- Implement functions to calculate entropy and information gain\n",
    "- What is the class entropy for the entire dataset? What is the information gain when you split the data using the *Water* feature?\n",
    "- Implement a basic decision tree:\n",
    "    - Select a feature to split on according to its information gain. If multiple features are equally good, select the leftmost one.\n",
    "    - Split the data and repeat until the tree is complete.\n",
    "    - Print out the results (nodes and splits).\n",
    "- Now train a scikit-learn decision tree on the same data. Do you get the same result? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sky</th>\n",
       "      <th>AirTemp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Water</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>Date?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>warm</td>\n",
       "      <td>normal</td>\n",
       "      <td>strong</td>\n",
       "      <td>warm</td>\n",
       "      <td>same</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>warm</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>warm</td>\n",
       "      <td>same</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rainy</td>\n",
       "      <td>warm</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>cool</td>\n",
       "      <td>change</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sunny</td>\n",
       "      <td>cold</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>warm</td>\n",
       "      <td>change</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sunny</td>\n",
       "      <td>warm</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>warm</td>\n",
       "      <td>same</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sky AirTemp Humidity    Wind Water Forecast Date?\n",
       "0  sunny    warm   normal  strong  warm     same   yes\n",
       "1  sunny    warm     high  strong  warm     same   yes\n",
       "2  rainy    warm     high  strong  cool   change    no\n",
       "3  sunny    cold     high  strong  warm   change   yes\n",
       "4  sunny    warm   normal    weak  warm     same    no"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Sky\":['sunny','sunny','rainy','sunny','sunny'],\n",
    "                   \"AirTemp\":['warm','warm','warm','cold','warm'],\n",
    "                   \"Humidity\":['normal','high','high','high','normal'],\n",
    "                   \"Wind\":['strong','strong','strong','strong','weak'],\n",
    "                   \"Water\":['warm','warm','cool','warm','warm'],\n",
    "                   \"Forecast\":['same','same','change','change','same'],\n",
    "                   \"Date?\":['yes','yes','no','yes','no']\n",
    "                   });\n",
    "# Fix column ordering\n",
    "df = df[['Sky', 'AirTemp', 'Humidity', 'Wind', 'Water', 'Forecast', 'Date?']] \n",
    "df # print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete these functions first\n",
    "# pos and neg are the number of positive and negative samples in a node\n",
    "def entropy(pos, neg):\n",
    "    return 0\n",
    "\n",
    "# pos1 and pos2 are the number of positive examples in each branch after the split. \n",
    "# Same for neg1 and neg2 \n",
    "def info_gain(pos1,neg1,pos2,neg2):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests (4 points (1+1+2))\n",
    "Study the effect of the number of trees in a RandomForest on the EEG-eye-state dataset (http://www.openml.org/d/1471). This dataset measures brain activity using 15 sensors, and you need to predict whether the person's eyes are open or closed. \n",
    "\n",
    "* Train a RandomForest classifier on this dataset with an increasing number of trees (on a log scale as above). Plot the Out-Of-Bag error against the number of trees.\n",
    "    - The Out-Of-Bag error is the test error obtained when using bootstrapping, and using the non-drawn data points as the test set. This is what a RandomForest does internally, so you can retrieve it from the classifier. The code below hints on how to do this.\n",
    "* Construct the same plot, but now use 10-fold Cross-validation and error rate instead of the OOB error. Compare the two. What do you learn from this?\n",
    "* Compare the performance of the RandomForest ensemble with that of a single full decision tree. Compute the AUC as well as the bias and variance. Does the bias and variance increase/decrease for the ensemble? Does the number of trees affect the result?\n",
    "\n",
    "Hint: Error rate = 1 - accuracy. It is not a standard scoring metric for ```cross_val_score```, so you'll need to let it compute the accuracy values, and then compute the mean error rate yourself.  \n",
    "Hint: We discussed bias-variance decomposition in class. It is not included in scikit-learn, so you'll need to implement it yourself. Always first calculate the bias and variance of each sample individually, and then sum them up. An example is show in the notebook of lecture 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eeg = oml.datasets.get_dataset(1471) # Download Ionosphere data\n",
    "X, y = eeg.get_data(target=eeg.default_target_attribute);\n",
    "\n",
    "# Out of bag errors can be retrieved from the RandomForest classifier. \n",
    "# You'll need to loop over the number of trees.\n",
    "# http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "from sklearn import ensemble\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "clf.fit(X, y)\n",
    "(1 - clf.oob_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A regression benchmark (1 point)\n",
    "Consider the liver-disorder dataset (http://www.openml.org/d/8). The goal is to predict how much alcohol someone consumed based on blood test values.\n",
    "\n",
    "- Take a selection of the algorithms that we covered in class that can do regression.\n",
    "- Based on what you learned in the previous exercises, make educated guesses about good hyperparameter values and set up a grid or random search.\n",
    "- Evaluate all models with 10-fold cross-validation and root mean squared error (RMSE). Report all results. Which model yields the best results?\n",
    "\n",
    "Hint: nagmean squared error (MSE) is a standard scoring technique in ```GridSearchCV``` and ```cross_val_score```. You'll have to compute the square roots yourself. Of course, during a grid search you can just use MSE, the optimal hyperparameter values will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liver = oml.datasets.get_dataset(8) # Download Liver-disorders data\n",
    "X, y = liver.get_data(target=liver.default_target_attribute);"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
